{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xSYZ2GF7ZkfT"
   },
   "source": [
    "#  **SM64 Speedruns - A Python Test**\n",
    "\n",
    "\\** **Ignore any redundant / unnecessary comments, they're mainly just notes for me because I am a noob :]**\n",
    "\n",
    "Learning Python for data analysis / science and wanted to test what I've learned so far on a personal project using a dataset from Kaggle. (https://www.kaggle.com/code/mcpenguin/super-mario-64-speedruns-data-collection)\n",
    "\\\n",
    "\\\n",
    "I also haven't used git in a while so this is also sort of a guinea pig for re-learning that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t7s5LlY3xn9p"
   },
   "source": [
    "### **SQLite Connection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything from lines 22 - 48 is to ensure the data doesn't append to the data already present in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "# Learned the purpose of importing an aliased [module].[interface] and then just the [module], but with a diff alias.\n",
    "# -- Mainly to access separate operations of the module. i.e. changing the graph's style with mpl, and access the plotting operations with plt.\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import csv, openpyxl\n",
    "import sqlite3\n",
    "import os, glob\n",
    "import dateutil, datetime\n",
    "\n",
    "# Connection Object to establish connection to a sqlite3 database.\n",
    "connObj = sqlite3.connect('SPEEDRUNS.db')\n",
    "cursorObj = connObj.cursor()\n",
    "\n",
    "%reload_ext sql\n",
    "%sql sqlite:///SPEEDRUNS.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "qZaOoO2SECZX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///SPEEDRUNS.db\n",
      "Done.\n",
      "0\n",
      "./Data/ALL_CATEGORIES.csv\n"
     ]
    }
   ],
   "source": [
    "# Assigning the datasets location for SM64 Speedruns to a variable called \"repo\"\n",
    "repo = r'./Data/'\n",
    "full_path_to_dataset = os.path.join(repo, 'ALL_CATEGORIES.csv')\n",
    "\n",
    "# Checking if there is data already in the table (mainly for testing + it's just a sqlite table)\n",
    "result = %sql SELECT COUNT(*) FROM ALL_CAT_SPEEDRUNS\n",
    "\n",
    "# Extract the count from the result set\n",
    "count_result = result[0][0] if result is not None and len(result) > 0 else 0\n",
    "\n",
    "print(count_result)\n",
    "print(full_path_to_dataset)\n",
    "\n",
    "cursorObj.execute('''CREATE TABLE IF NOT EXISTS ALL_CAT_SPEEDRUNS (\n",
    "    'RUN_ID' INTEGER PRIMARY KEY,\n",
    "    'Unnamed: 1' INTEGER,\n",
    "    'id' VARCHAR(50),\n",
    "    'place' INTEGER,\n",
    "    'speedrun_link' VARCHAR(200),\n",
    "    'submitted_date' DATETIME,\n",
    "    'primary_time_seconds' FLOAT,\n",
    "    'real_time_seconds' FLOAT,\n",
    "    'player_id' VARCHAR(50),\n",
    "    'player_name' VARCHAR(50),\n",
    "    'player_country' VARCHAR(50),\n",
    "    'platform' CHAR(6),\n",
    "    'verified' BOOL\n",
    "    )''')\n",
    "connObj.commit()\n",
    "\n",
    "# If there is data, delete it\n",
    "if count_result > 0:\n",
    "    if os.path.isfile(full_path_to_dataset):\n",
    "       os.remove(full_path_to_dataset)\n",
    "       %sql DELETE FROM ALL_CAT_SPEEDRUNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y0yMNxp-xD-1"
   },
   "source": [
    "###**Merging Separate .CSV Files Into A Single Pandas DataFrame.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ixz7XI5WzP7X"
   },
   "source": [
    "**Gathering Datasets (.CSV)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "BTzzXmTIw6vU"
   },
   "outputs": [],
   "source": [
    "# Lists files within the specified directory, in this case \"repo\".\n",
    "files_in_repo = os.listdir(repo)\n",
    "\n",
    "# Looping through files_in_repo and assignging it to the csv_files List only if the file ends with .csv.\n",
    "csv_files = [f for f in files_in_repo if f.endswith('.csv')]\n",
    "\n",
    "# List to hold the list of dataframes / csv files.\n",
    "df_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VsYcndtAJ8Wi"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8AOPnExzZOR"
   },
   "source": [
    "**Appending Separate .CSV DataFrames to the \"df_list\" List via For Loop**\n",
    "\n",
    "Found this online because I wasn't sure of the syntax on doing the loop, and the error handling is good, too.\n",
    "\n",
    "It all makes sense though - here's my walkthrough:\n",
    "\n",
    "1.   Looping through the list of `csv_files` within `repo`, assigning each to \"`csv`\".\n",
    "\n",
    "2.   The path to the file is created by joining the `repo` path and the .csv filename.\n",
    "\n",
    "1.   Creating a DataFrame (for each iteration of `csv_files`) using the `read_csv()` function and the `file_path` variable.\n",
    "2.   The DataFrame is appended to the DataFrame List `df_list`.\n",
    "\n",
    "1.   `try` / `except` = error handling on the encoding types for the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "i_RtsondzSwd"
   },
   "outputs": [],
   "source": [
    "for csv in csv_files:\n",
    "    file_path = os.path.join(repo, csv)\n",
    "    try:\n",
    "        # Try reading the file using default UTF-8 encoding\n",
    "        df = pd.read_csv(file_path)\n",
    "        df_list.append(df)\n",
    "    except UnicodeDecodeError:\n",
    "        try:\n",
    "            # If UTF-8 fails, try reading the file using UTF-16 encoding with tab separator\n",
    "            df = pd.read_csv(file_path, sep='\\t', encoding='utf-16')\n",
    "            df_list.append(df)\n",
    "        except Exception as e:\n",
    "            # Learned that \"f\" before a string allows the use of variables (wrapped in curly braces)\n",
    "            print(f\"Could not read file {csv} because of error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not read file {csv} because of error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIds9nF_KAj_"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jcXFZhq02N4x"
   },
   "source": [
    "**Concatenating the DataFrames and Saving to a Single .CSV File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "PAnDXNQ722Fq"
   },
   "outputs": [],
   "source": [
    "# Concat all data into a single DataFrame\n",
    "complete_df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tin1-RAhKDdC"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgN2dFgiMYSH"
   },
   "source": [
    "### **Cleansing / Restructuring Data With *Pandas***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "3PWVTa7MqNzn"
   },
   "outputs": [],
   "source": [
    "# Save the final result to a new .csv file (appears in the G Drive folder after 15-30 sec).\n",
    "complete_df.to_csv(full_path_to_dataset, index=False)\n",
    "\n",
    "# Reading in the '/content/drive/MyDrive/Kaggle/Datasets/SM64 Speedruns/ALL_CATEGORIES.csv' file and storing into a dataframe.\n",
    "df = pd.read_csv(full_path_to_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "XCPzCcFuX_5d",
    "outputId": "cf4a6c5b-ac71-41bf-a3fe-33b05c9040cb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PLAYER_NAME</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>RUN_TIME</th>\n",
       "      <th>SUBMISSION_DATE</th>\n",
       "      <th>PLACE</th>\n",
       "      <th>PLATFORM</th>\n",
       "      <th>VERIFIED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Karin</td>\n",
       "      <td>Japan</td>\n",
       "      <td>5808.0</td>\n",
       "      <td>2023-10-21T08:50:34Z</td>\n",
       "      <td>1</td>\n",
       "      <td>N64</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>marlene</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5823.0</td>\n",
       "      <td>2023-10-22T09:45:36Z</td>\n",
       "      <td>2</td>\n",
       "      <td>N64</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Liam</td>\n",
       "      <td>United States</td>\n",
       "      <td>5837.0</td>\n",
       "      <td>2023-11-23T15:29:50Z</td>\n",
       "      <td>3</td>\n",
       "      <td>N64</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>puncayshun</td>\n",
       "      <td>United States</td>\n",
       "      <td>5854.0</td>\n",
       "      <td>2023-10-14T00:11:51Z</td>\n",
       "      <td>4</td>\n",
       "      <td>N64</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Weegee</td>\n",
       "      <td>United States</td>\n",
       "      <td>5855.0</td>\n",
       "      <td>2022-11-18T22:01:40Z</td>\n",
       "      <td>5</td>\n",
       "      <td>N64</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2511</th>\n",
       "      <td>2008</td>\n",
       "      <td>disrespectless</td>\n",
       "      <td>Germany</td>\n",
       "      <td>3186.0</td>\n",
       "      <td>2018-09-07T13:43:48Z</td>\n",
       "      <td>497</td>\n",
       "      <td>N64</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512</th>\n",
       "      <td>2009</td>\n",
       "      <td>YUKING</td>\n",
       "      <td>Japan</td>\n",
       "      <td>3187.0</td>\n",
       "      <td>2019-09-29T05:59:03Z</td>\n",
       "      <td>498</td>\n",
       "      <td>N64</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>2010</td>\n",
       "      <td>asandal</td>\n",
       "      <td>United States</td>\n",
       "      <td>3187.0</td>\n",
       "      <td>2022-04-16T10:09:01Z</td>\n",
       "      <td>498</td>\n",
       "      <td>N64</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>2011</td>\n",
       "      <td>Oxelput</td>\n",
       "      <td>Germany</td>\n",
       "      <td>3188.0</td>\n",
       "      <td>2023-06-10T21:33:10Z</td>\n",
       "      <td>500</td>\n",
       "      <td>N64</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2515</th>\n",
       "      <td>2012</td>\n",
       "      <td>nahottv</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>3188.0</td>\n",
       "      <td>2023-11-08T10:50:28Z</td>\n",
       "      <td>500</td>\n",
       "      <td>EMU</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2516 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID     PLAYER_NAME        COUNTRY  RUN_TIME       SUBMISSION_DATE  \\\n",
       "0        1           Karin          Japan    5808.0  2023-10-21T08:50:34Z   \n",
       "1        2         marlene            NaN    5823.0  2023-10-22T09:45:36Z   \n",
       "2        3            Liam  United States    5837.0  2023-11-23T15:29:50Z   \n",
       "3        4      puncayshun  United States    5854.0  2023-10-14T00:11:51Z   \n",
       "4        5          Weegee  United States    5855.0  2022-11-18T22:01:40Z   \n",
       "...    ...             ...            ...       ...                   ...   \n",
       "2511  2008  disrespectless        Germany    3186.0  2018-09-07T13:43:48Z   \n",
       "2512  2009          YUKING          Japan    3187.0  2019-09-29T05:59:03Z   \n",
       "2513  2010         asandal  United States    3187.0  2022-04-16T10:09:01Z   \n",
       "2514  2011         Oxelput        Germany    3188.0  2023-06-10T21:33:10Z   \n",
       "2515  2012         nahottv       Scotland    3188.0  2023-11-08T10:50:28Z   \n",
       "\n",
       "      PLACE PLATFORM VERIFIED  \n",
       "0         1      N64      Yes  \n",
       "1         2      N64      Yes  \n",
       "2         3      N64      Yes  \n",
       "3         4      N64      Yes  \n",
       "4         5      N64      Yes  \n",
       "...     ...      ...      ...  \n",
       "2511    497      N64      Yes  \n",
       "2512    498      N64      Yes  \n",
       "2513    498      N64      Yes  \n",
       "2514    500      N64      Yes  \n",
       "2515    500      EMU      Yes  \n",
       "\n",
       "[2516 rows x 8 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping columns I do not need. The if statement could check if each col is in the df but i didn't want to list them all. This is just so it doesn't error when testing anyway.\n",
    "if 'speedrun_link' in df:\n",
    "    cols_to_drop = ['Unnamed: 1',\n",
    "                    'id',\n",
    "                    'player_id',\n",
    "                    'speedrun_link',\n",
    "                    'primary_time_seconds']\n",
    "else:\n",
    "    cols_to_drop = []\n",
    "\n",
    "df.drop(cols_to_drop, inplace=True, axis=1)\n",
    "\n",
    "# Renaming the columns a bit.\n",
    "df = df.rename(columns={'RUN_ID': 'ID', 'player_name': 'PLAYER_NAME', 'player_country': 'COUNTRY', 'real_time_seconds': 'RUN_TIME', 'submitted_date': 'SUBMISSION_DATE', 'place': 'PLACE', 'platform': 'PLATFORM', 'verified': 'VERIFIED'})\n",
    "\n",
    "# Rearranging columns to an order I like.\n",
    "df.iloc[:,[0,4,5,3,2,1,6,7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C_UNbYTWcKkn",
    "outputId": "6748c2ba-3e82-4e18-90a3-b694f899d6a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2516"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the dataframe into the SPEEDRUNS database using the connObj. Specified a table name of \"ALL_CAT_SPEEDRUNS\".\n",
    "df.to_sql('ALL_CAT_SPEEDRUNS', connObj, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "wvchqtVfbtje"
   },
   "outputs": [],
   "source": [
    "# Updating the RUN_TIME column with the \"real\" time in %H:MM:SS format\n",
    "cursorObj.execute('''SELECT COUNT(*) FROM ALL_CAT_SPEEDRUNS''')\n",
    "row_count = cursorObj.fetchone()[0]\n",
    "\n",
    "cursorObj.execute('''SELECT ID, RUN_TIME FROM ALL_CAT_SPEEDRUNS''')\n",
    "run_times = cursorObj.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "o0rD9dMMkDOl"
   },
   "outputs": [],
   "source": [
    "for rt in run_times:\n",
    "    real_time = str(datetime.timedelta(seconds = rt[1]))\n",
    "    run_id = rt[0]\n",
    "    cursorObj.execute(f'''UPDATE ALL_CAT_SPEEDRUNS SET RUN_TIME = \"{real_time}\" WHERE ID = {run_id};''')\n",
    "connObj.commit()\n",
    "\n",
    "df = pd.read_sql('SELECT * FROM ALL_CAT_SPEEDRUNS ORDER BY ID ASC', connObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "EVQrdyhXfuWa",
    "outputId": "71c7e91c-407f-4caf-fbfc-35a6e1db86b5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PLACE</th>\n",
       "      <th>SUBMISSION_DATE</th>\n",
       "      <th>RUN_TIME</th>\n",
       "      <th>PLAYER_NAME</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>PLATFORM</th>\n",
       "      <th>VERIFIED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-10-21T08:50:34Z</td>\n",
       "      <td>1:36:48</td>\n",
       "      <td>Karin</td>\n",
       "      <td>Japan</td>\n",
       "      <td>N64</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-10-22T09:45:36Z</td>\n",
       "      <td>1:37:03</td>\n",
       "      <td>marlene</td>\n",
       "      <td>None</td>\n",
       "      <td>N64</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-11-23T15:29:50Z</td>\n",
       "      <td>1:37:17</td>\n",
       "      <td>Liam</td>\n",
       "      <td>United States</td>\n",
       "      <td>N64</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-10-14T00:11:51Z</td>\n",
       "      <td>1:37:34</td>\n",
       "      <td>puncayshun</td>\n",
       "      <td>United States</td>\n",
       "      <td>N64</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-11-18T22:01:40Z</td>\n",
       "      <td>1:37:35</td>\n",
       "      <td>Weegee</td>\n",
       "      <td>United States</td>\n",
       "      <td>N64</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2511</th>\n",
       "      <td>2508</td>\n",
       "      <td>497</td>\n",
       "      <td>2020-12-05T15:12:03Z</td>\n",
       "      <td>2:03:49</td>\n",
       "      <td>Linkx2</td>\n",
       "      <td>Germany</td>\n",
       "      <td>N64</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512</th>\n",
       "      <td>2509</td>\n",
       "      <td>498</td>\n",
       "      <td>2014-12-17T03:22:18Z</td>\n",
       "      <td>2:03:51</td>\n",
       "      <td>TPositive</td>\n",
       "      <td>United States</td>\n",
       "      <td>VC</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>2510</td>\n",
       "      <td>499</td>\n",
       "      <td>2022-06-16T09:32:31Z</td>\n",
       "      <td>2:04:04</td>\n",
       "      <td>NaturallyAllen</td>\n",
       "      <td>United States</td>\n",
       "      <td>EMU</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>2511</td>\n",
       "      <td>500</td>\n",
       "      <td>2019-02-11T01:26:52Z</td>\n",
       "      <td>2:04:05</td>\n",
       "      <td>meowmix_fan</td>\n",
       "      <td>United States</td>\n",
       "      <td>VC</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2515</th>\n",
       "      <td>2512</td>\n",
       "      <td>500</td>\n",
       "      <td>2023-03-17T19:03:02Z</td>\n",
       "      <td>2:04:05</td>\n",
       "      <td>Kosmic</td>\n",
       "      <td>United States</td>\n",
       "      <td>N64</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2516 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  PLACE       SUBMISSION_DATE RUN_TIME     PLAYER_NAME  \\\n",
       "0        1      1  2023-10-21T08:50:34Z  1:36:48           Karin   \n",
       "1        2      2  2023-10-22T09:45:36Z  1:37:03         marlene   \n",
       "2        3      3  2023-11-23T15:29:50Z  1:37:17            Liam   \n",
       "3        4      4  2023-10-14T00:11:51Z  1:37:34      puncayshun   \n",
       "4        5      5  2022-11-18T22:01:40Z  1:37:35          Weegee   \n",
       "...    ...    ...                   ...      ...             ...   \n",
       "2511  2508    497  2020-12-05T15:12:03Z  2:03:49          Linkx2   \n",
       "2512  2509    498  2014-12-17T03:22:18Z  2:03:51       TPositive   \n",
       "2513  2510    499  2022-06-16T09:32:31Z  2:04:04  NaturallyAllen   \n",
       "2514  2511    500  2019-02-11T01:26:52Z  2:04:05     meowmix_fan   \n",
       "2515  2512    500  2023-03-17T19:03:02Z  2:04:05          Kosmic   \n",
       "\n",
       "            COUNTRY PLATFORM VERIFIED  \n",
       "0             Japan      N64      Yes  \n",
       "1              None      N64      Yes  \n",
       "2     United States      N64      Yes  \n",
       "3     United States      N64      Yes  \n",
       "4     United States      N64      Yes  \n",
       "...             ...      ...      ...  \n",
       "2511        Germany      N64      Yes  \n",
       "2512  United States       VC      Yes  \n",
       "2513  United States      EMU      Yes  \n",
       "2514  United States       VC      Yes  \n",
       "2515  United States      N64      Yes  \n",
       "\n",
       "[2516 rows x 8 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
