{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xSYZ2GF7ZkfT"
   },
   "source": [
    "#  **SM64 Speedruns - A Python Test**\n",
    "\n",
    "\\** **Ignore any redundant / unnecessary comments, they're mainly just notes for me because I am a noob :]**\n",
    "\n",
    "Learning Python for data analysis / science and wanted to test what I've learned so far on a personal project using a dataset from Kaggle. (https://www.kaggle.com/code/mcpenguin/super-mario-64-speedruns-data-collection)\n",
    "\\\n",
    "\\\n",
    "I also haven't used git in a while so this is also sort of a guinea pig for re-learning that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Gather and Cleanse Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t7s5LlY3xn9p"
   },
   "source": [
    "### **SQLite Connection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "# Learned the purpose of importing an aliased [module].[interface] and then just the [module], but with a diff alias.\n",
    "# -- Mainly to access separate operations of the module. i.e. changing the graph's style with mpl, and access the plotting operations with plt.\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import csv, openpyxl\n",
    "import sqlite3\n",
    "import os, glob\n",
    "import dateutil, datetime\n",
    "\n",
    "# Connection Object to establish connection to a sqlite3 database.\n",
    "connObj = sqlite3.connect('SPEEDRUNS.db')\n",
    "cursorObj = connObj.cursor()\n",
    "\n",
    "%load_ext sql\n",
    "%sql sqlite:///SPEEDRUNS.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qZaOoO2SECZX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///SPEEDRUNS.db\n",
      "Done.\n",
      " * sqlite:///SPEEDRUNS.db\n",
      "2274 rows affected.\n"
     ]
    }
   ],
   "source": [
    "# Assigning the datasets location for SM64 Speedruns to a variable called \"repo\"\n",
    "repo = r'./Data/'\n",
    "full_path_to_dataset = os.path.join(repo, 'ALL_CATEGORIES.csv')\n",
    "\n",
    "# Checking if there is data already in the table (mainly for testing + it's just a sqlite table)\n",
    "result = %sql SELECT COUNT(*) FROM ALL_CAT_SPEEDRUNS\n",
    "\n",
    "# Extract the count from the result set\n",
    "count_result = result[0][0] if result is not None and len(result) > 0 else 0\n",
    "\n",
    "cursorObj.execute('''CREATE TABLE IF NOT EXISTS ALL_CAT_SPEEDRUNS (\n",
    "    'run_id' INTEGER PRIMARY KEY,\n",
    "    'Category' VARCHAR(20),\n",
    "    'id' VARCHAR(50),\n",
    "    'place' INTEGER,\n",
    "    'speedrun_link' VARCHAR(200),\n",
    "    'submitted_date' DATETIME,\n",
    "    'primary_time_seconds' FLOAT,\n",
    "    'real_time_seconds' FLOAT,\n",
    "    'player_id' VARCHAR(50),\n",
    "    'player_name' VARCHAR(50),\n",
    "    'player_country' VARCHAR(50),\n",
    "    'platform' CHAR(6),\n",
    "    'verified' BOOL\n",
    "    )''')\n",
    "connObj.commit()\n",
    "\n",
    "# If there is data, delete it\n",
    "if count_result > 0:\n",
    "    if os.path.isfile(full_path_to_dataset):\n",
    "       os.remove(full_path_to_dataset)\n",
    "       %sql DELETE FROM ALL_CAT_SPEEDRUNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y0yMNxp-xD-1"
   },
   "source": [
    "###**Merging Separate .CSV Files Into A Single Pandas DataFrame.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ixz7XI5WzP7X"
   },
   "source": [
    "**Gathering Datasets (.CSV)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BTzzXmTIw6vU"
   },
   "outputs": [],
   "source": [
    "# Lists files within the specified directory, in this case \"repo\".\n",
    "files_in_repo = os.listdir(repo)\n",
    "\n",
    "# Looping through files_in_repo and assignging it to the csv_files List only if the file ends with .csv.\n",
    "csv_files = [f for f in files_in_repo if f.endswith('.csv')]\n",
    "\n",
    "# List to hold the list of dataframes / csv files.\n",
    "df_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VsYcndtAJ8Wi"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8AOPnExzZOR"
   },
   "source": [
    "**Appending Separate .CSV DataFrames to the \"df_list\" List via For Loop**\n",
    "\n",
    "Found this online because I wasn't sure of the syntax on doing the loop, and the error handling is good, too.\n",
    "\n",
    "It all makes sense though - here's my walkthrough:\n",
    "\n",
    "1.   Looping through the list of `csv_files` within `repo`, assigning each to \"`csv`\".\n",
    "\n",
    "2.   The path to the file is created by joining the `repo` path and the .csv filename.\n",
    "\n",
    "1.   Creating a DataFrame (for each iteration of `csv_files`) using the `read_csv()` function and the `file_path` variable.\n",
    "2.   The DataFrame is appended to the DataFrame List `df_list`.\n",
    "\n",
    "1.   `try` / `except` = error handling on the encoding types for the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "i_RtsondzSwd"
   },
   "outputs": [],
   "source": [
    "for csv in csv_files:\n",
    "    file_path = os.path.join(repo, csv)\n",
    "    try:\n",
    "        # Try reading the file using default UTF-8 encoding\n",
    "        df = pd.read_csv(file_path)\n",
    "        df_list.append(df)\n",
    "    except UnicodeDecodeError:\n",
    "        try:\n",
    "            # If UTF-8 fails, try reading the file using UTF-16 encoding with tab separator\n",
    "            df = pd.read_csv(file_path, sep='\\t', encoding='utf-16')\n",
    "            df_list.append(df)\n",
    "        except Exception as e:\n",
    "            # Learned that \"f\" before a string allows the use of variables (wrapped in curly braces)\n",
    "            print(f\"Could not read file {csv} because of error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not read file {csv} because of error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIds9nF_KAj_"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jcXFZhq02N4x"
   },
   "source": [
    "**Concatenating the DataFrames and Saving to a Single .CSV File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PAnDXNQ722Fq"
   },
   "outputs": [],
   "source": [
    "# Concat all data into a single DataFrame\n",
    "complete_df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tin1-RAhKDdC"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgN2dFgiMYSH"
   },
   "source": [
    "### **Cleansing / Restructuring Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3PWVTa7MqNzn"
   },
   "outputs": [],
   "source": [
    "# Save the final result to a new .csv file (appears in the G Drive folder after 15-30 sec).\n",
    "complete_df.to_csv(full_path_to_dataset, index=False)\n",
    "\n",
    "# Reading in the '/content/drive/MyDrive/Kaggle/Datasets/SM64 Speedruns/ALL_CATEGORIES.csv' file and storing into a dataframe.\n",
    "df = pd.read_csv(full_path_to_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "XCPzCcFuX_5d",
    "outputId": "cf4a6c5b-ac71-41bf-a3fe-33b05c9040cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2274"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping columns I do not need. The if statement could check if each col is in the df but i didn't want to list them all. This is just so it doesn't error when testing anyway.\n",
    "if 'speedrun_link' in df:\n",
    "    cols_to_drop = ['id',\n",
    "                    'player_id',\n",
    "                    'speedrun_link',\n",
    "                    'primary_time_seconds']\n",
    "else:\n",
    "    cols_to_drop = []\n",
    "\n",
    "df.drop(cols_to_drop, inplace=True, axis=1)\n",
    "\n",
    "# Renaming the columns a bit.\n",
    "df = df.rename(columns={'run_id': 'ID', 'Category': 'CATEGORY', 'player_name': 'PLAYER_NAME', 'player_country': 'COUNTRY', 'real_time_seconds': 'RUN_TIME', 'submitted_date': 'SUBMISSION_DATE', 'place': 'PLACE', 'platform': 'PLATFORM', 'verified': 'VERIFIED'})\n",
    "\n",
    "# Some players don't have their country set up on speedrun.com so sqlite sets these to NaN. I'd rather it be null / none.\n",
    "cursorObj.execute('''UPDATE ALL_CAT_SPEEDRUNS SET COUNTRY = \"\" WHERE COUNTRY = \"NaN\"''')\n",
    "connObj.commit()\n",
    "\n",
    "df.to_sql('ALL_CAT_SPEEDRUNS', connObj, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true,
    "id": "o0rD9dMMkDOl",
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#---------------------------[0]----[1]\n",
    "cursorObj.execute('''SELECT ID, RUN_TIME FROM ALL_CAT_SPEEDRUNS''')\n",
    "\n",
    "# Stored as a 2X2 list.\n",
    "run_times = cursorObj.fetchall()\n",
    "\n",
    "for rt in run_times:\n",
    "    # Set the \"real_time\" to a formatted time (as string). rt[1] is the RUN_TIME from the table.\n",
    "    real_time = str(datetime.timedelta(seconds = rt[1]))\n",
    "    # Set the \"run_id\" to the rt[0] value in the run_times list. Same as the above, just a different index.\n",
    "    run_id = rt[0]\n",
    "    # Run an UPDATE statement for each run time and update the RUN_TIME using the variable set previously.\n",
    "    cursorObj.execute(f'''UPDATE ALL_CAT_SPEEDRUNS SET RUN_TIME = \"{real_time}\" WHERE ID = {run_id};''')\n",
    "connObj.commit()\n",
    "\n",
    "# Reordering columns in the dataframe\n",
    "df = pd.read_sql('SELECT ID, CATEGORY, PLACE, PLAYER_NAME, RUN_TIME, PLATFORM, COUNTRY, SUBMISSION_DATE, VERIFIED FROM ALL_CAT_SPEEDRUNS ORDER BY ID ASC', connObj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Date / Time Cleanup**\n",
    "\n",
    "I was originally going to remove the first two chars as well (the 0:) hours for 0/1 star, but then realized that there are times over an hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>PLACE</th>\n",
       "      <th>PLAYER_NAME</th>\n",
       "      <th>RUN_TIME</th>\n",
       "      <th>PLATFORM</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>SUBMISSION_DATE</th>\n",
       "      <th>VERIFIED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0 Star</td>\n",
       "      <td>1</td>\n",
       "      <td>Suigi</td>\n",
       "      <td>0:06:16.600</td>\n",
       "      <td>N64</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2023-10-27</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0 Star</td>\n",
       "      <td>2</td>\n",
       "      <td>KANNO</td>\n",
       "      <td>0:06:27.380</td>\n",
       "      <td>N64</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-02-12</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0 Star</td>\n",
       "      <td>3</td>\n",
       "      <td>cjrokokomero</td>\n",
       "      <td>0:06:28.130</td>\n",
       "      <td>N64</td>\n",
       "      <td>Italy</td>\n",
       "      <td>2023-06-19</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0 Star</td>\n",
       "      <td>4</td>\n",
       "      <td>Parsee02</td>\n",
       "      <td>0:06:30.650</td>\n",
       "      <td>N64</td>\n",
       "      <td>Japan</td>\n",
       "      <td>2023-07-11</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0 Star</td>\n",
       "      <td>5</td>\n",
       "      <td>Dowsky</td>\n",
       "      <td>0:06:32.150</td>\n",
       "      <td>N64</td>\n",
       "      <td>United States</td>\n",
       "      <td>2020-09-19</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269</th>\n",
       "      <td>2266</td>\n",
       "      <td>120 Star</td>\n",
       "      <td>497</td>\n",
       "      <td>Linkx2</td>\n",
       "      <td>2:03:49</td>\n",
       "      <td>N64</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-12-05</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270</th>\n",
       "      <td>2267</td>\n",
       "      <td>120 Star</td>\n",
       "      <td>498</td>\n",
       "      <td>TPositive</td>\n",
       "      <td>2:03:51</td>\n",
       "      <td>VC</td>\n",
       "      <td>United States</td>\n",
       "      <td>2014-12-17</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>2268</td>\n",
       "      <td>120 Star</td>\n",
       "      <td>499</td>\n",
       "      <td>NaturallyAllen</td>\n",
       "      <td>2:04:04</td>\n",
       "      <td>EMU</td>\n",
       "      <td>United States</td>\n",
       "      <td>2022-06-16</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2272</th>\n",
       "      <td>2269</td>\n",
       "      <td>120 Star</td>\n",
       "      <td>500</td>\n",
       "      <td>meowmix_fan</td>\n",
       "      <td>2:04:05</td>\n",
       "      <td>VC</td>\n",
       "      <td>United States</td>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>2270</td>\n",
       "      <td>120 Star</td>\n",
       "      <td>500</td>\n",
       "      <td>Kosmic</td>\n",
       "      <td>2:04:05</td>\n",
       "      <td>N64</td>\n",
       "      <td>United States</td>\n",
       "      <td>2023-03-17</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2274 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  CATEGORY  PLACE     PLAYER_NAME     RUN_TIME PLATFORM  \\\n",
       "0        1    0 Star      1           Suigi  0:06:16.600      N64   \n",
       "1        2    0 Star      2           KANNO  0:06:27.380      N64   \n",
       "2        3    0 Star      3    cjrokokomero  0:06:28.130      N64   \n",
       "3        4    0 Star      4        Parsee02  0:06:30.650      N64   \n",
       "4        5    0 Star      5          Dowsky  0:06:32.150      N64   \n",
       "...    ...       ...    ...             ...          ...      ...   \n",
       "2269  2266  120 Star    497          Linkx2      2:03:49      N64   \n",
       "2270  2267  120 Star    498       TPositive      2:03:51       VC   \n",
       "2271  2268  120 Star    499  NaturallyAllen      2:04:04      EMU   \n",
       "2272  2269  120 Star    500     meowmix_fan      2:04:05       VC   \n",
       "2273  2270  120 Star    500          Kosmic      2:04:05      N64   \n",
       "\n",
       "            COUNTRY SUBMISSION_DATE VERIFIED  \n",
       "0            Canada      2023-10-27      Yes  \n",
       "1              None      2022-02-12      Yes  \n",
       "2             Italy      2023-06-19      Yes  \n",
       "3             Japan      2023-07-11      Yes  \n",
       "4     United States      2020-09-19      Yes  \n",
       "...             ...             ...      ...  \n",
       "2269        Germany      2020-12-05      Yes  \n",
       "2270  United States      2014-12-17      Yes  \n",
       "2271  United States      2022-06-16      Yes  \n",
       "2272  United States      2019-02-11      Yes  \n",
       "2273  United States      2023-03-17      Yes  \n",
       "\n",
       "[2274 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I only want to do this to times that require this amount of precision (only 1 and 0 star).\n",
    "def TrimLastThree(value):\n",
    "    if '.' in value:\n",
    "        return value[:-3]\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "# Converting 'SUBMISSION_DATE' to datetime.\n",
    "df['SUBMISSION_DATE'] = pd.to_datetime(df['SUBMISSION_DATE']).dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Applying the TrimLastThree function to the 'RUN_TIME' column. Learned how to do this and it's cool, I also know somewhat of lambda functions.\n",
    "df_runtime = df['RUN_TIME'].apply(TrimLastThree)\n",
    "# Creating a dataframe out of the above result. \n",
    "df_runtime = pd.DataFrame(df_runtime)\n",
    "# Updating the df dataframe with the updated df_runtime values for the RUN_TIME column.\n",
    "df.update(df_runtime)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Analyze Data**\n",
    "\n",
    "*Need to figure out what meaning can be obtained from it so we can interpret it later using Matplotlib & Seaborn.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: Filter for only Verified runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: Find players who appear in more than one category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: Find the top 3 players in each category from each country."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: How do times compare across different countries? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5: Which countries have the best leaderboard rankings on average?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6: Find the difference in times for each platform (N64, EMU, VC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7: What is the greatest time gap between first and second place of each category? A.K.A., Who held the record the longest?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8: "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
